{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0d5e4ce-dae4-4fbc-88f1-23150539e8fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sine Wave Evolution Engine\n",
    "\n",
    "# Changes: added np.flip to the select function to sort greatest to least fitness\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import snntorch as snn\n",
    "import torch.nn as nn\n",
    "from snntorch import surrogate\n",
    "from snntorch import spikegen\n",
    "from snntorch import functional\n",
    "from snntorch import LIF\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "\n",
    "# # For game functions\n",
    "# import pygame\n",
    "import time\n",
    "\n",
    "import multiprocess as mp\n",
    "\n",
    "# ### Sine Wave Dataset\n",
    "# # Sine Wave Task Version: Explicit Time Resetting with period \n",
    "# class SineWaveDatasetLocal(Dataset):\n",
    "#     def __init__(self, csv_file):\n",
    "#         self.data = pd.read_csv(csv_file)\n",
    "#         self.num_timesteps = 100 # length of sine wave sequence\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         amplitude = self.data.iloc[idx, 0]\n",
    "#         sine_wave = eval(self.data.iloc[idx, 1])  \n",
    "        \n",
    "#         # L1: Explicit Time Resetting with period \n",
    "#         amplitude_vector = torch.tensor([amplitude] * self.num_timesteps, dtype=torch.float32)\n",
    "#         time_vector = torch.tensor([i for i in range(40)] * (self.num_timesteps//int(40)+1), dtype=torch.float32)\n",
    "#         time_vector = time_vector[:self.num_timesteps]\n",
    "#         sine_wave_vector = torch.tensor(sine_wave, dtype=torch.float32)\n",
    "        \n",
    "#         input_vector = torch.stack([amplitude_vector,time_vector],dim=1)  # Shape: [num_timesteps, 2]\n",
    "#         target_vector = torch.stack([sine_wave_vector],dim=1)\n",
    "#         return input_vector, sine_wave_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3404dace-f583-4136-8fc4-192d78e8dab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "### Building Connectivity and Neurons\n",
    "# creates a connection matrix with the specified sparseness for linear layers\n",
    "def conn_mx(rows, columns, sparseness):\n",
    "    # Calculate the number of non-zero entries based on sparseness\n",
    "    num_non_zero_entries = int(rows * columns * sparseness)\n",
    "\n",
    "    # Initialize the matrix with zeros\n",
    "    conn_mx = torch.zeros(rows, columns)\n",
    "\n",
    "    # Randomly select indices to set to the specified value\n",
    "    indices = torch.randperm(rows * columns)[:num_non_zero_entries]\n",
    "\n",
    "    # Initialize non-zero values using log normal distribution\n",
    "    mu = -0.64\n",
    "    sigma = 0.51\n",
    "    log_normal_values = torch.empty(indices.shape).normal_(mean=mu, std=sigma).exp_()\n",
    "    conn_mx.view(-1)[indices] = log_normal_values\n",
    "\n",
    "    return conn_mx\n",
    "\n",
    "# creates an excitatory and inhibitory matrix for reccurent layer\n",
    "def hid_mx(num_excitatory, num_inhibitory, num_iPV, num_iSst, num_iHtr, p_nn):\n",
    "    # Initialize the weight matrix\n",
    "    weight_matrix = np.zeros((num_excitatory + num_inhibitory, num_excitatory + num_inhibitory))\n",
    "\n",
    "    # Excitatory connections\n",
    "\n",
    "    # excitatory to excitatory\n",
    "    weight_matrix[:num_excitatory, :num_excitatory] = np.random.choice([0, 1], size=(num_excitatory, num_excitatory), p=[1-p_nn['e_e'], p_nn['e_e']])\n",
    "    # excitatory to inhibitory PV\n",
    "    weight_matrix[:num_excitatory, num_excitatory:num_excitatory+num_iPV] = np.random.choice([0, 1], size=(num_excitatory, num_iPV), p=[1-p_nn['e_PV'], p_nn['e_PV']])\n",
    "    # excitatory to inhibitory Sst\n",
    "    weight_matrix[:num_excitatory, num_excitatory+num_iPV:num_excitatory+num_iPV+num_iSst] = np.random.choice([0, 1], size=(num_excitatory, num_iSst), p=[1-p_nn['e_Sst'], p_nn['e_Sst']])\n",
    "    # excitatory to inhibitory Htr\n",
    "    weight_matrix[:num_excitatory, num_excitatory+num_iPV+num_iSst:] = np.random.choice([0, 1], size=(num_excitatory, num_iHtr), p=[1-p_nn['e_Htr'], p_nn['e_Htr']])\n",
    "\n",
    "\n",
    "    # Inhibitory connections\n",
    "\n",
    "    # inhibitory PV to excitatory\n",
    "    weight_matrix[num_excitatory:num_excitatory+num_iPV, :num_excitatory] = np.random.choice([0, -1], size=(num_iPV, num_excitatory), p=[1-p_nn['PV_e'], p_nn['PV_e']])\n",
    "    # inhibitory PV to inhibitory PV\n",
    "    weight_matrix[num_excitatory:num_excitatory+num_iPV, num_excitatory:num_excitatory+num_iPV] = np.random.choice([0, -1], size=(num_iPV, num_iPV), p=[1-p_nn['PV_PV'], p_nn['PV_PV']])\n",
    "    # inhibitory PV to inhibitory Htr\n",
    "    weight_matrix[num_excitatory:num_excitatory+num_iPV, num_excitatory+num_iPV:num_excitatory+num_iPV+num_iSst] = np.random.choice([0, -1], size=(num_iPV, num_iSst), p=[1-p_nn['PV_Sst'], p_nn['PV_Sst']])\n",
    "    # inhibitory PV to inhibitory Sst\n",
    "    weight_matrix[num_excitatory:num_excitatory+num_iPV, num_excitatory+num_iPV+num_iSst:] = np.random.choice([0, -1], size=(num_iPV, num_iHtr), p=[1-p_nn['PV_Htr'], p_nn['PV_Htr']]) \n",
    "\n",
    "    # inhibitory Sst to excitatory\n",
    "    weight_matrix[num_excitatory+num_iPV:num_excitatory+num_iPV+num_iSst, :num_excitatory] = np.random.choice([0, -1], size=(num_iSst, num_excitatory), p=[1-p_nn['Sst_e'], p_nn['Sst_e']])\n",
    "    # inhibitory Sst to inhibitory PV\n",
    "    weight_matrix[num_excitatory+num_iPV:num_excitatory+num_iPV+num_iSst, num_excitatory:num_excitatory+num_iPV] = np.random.choice([0, -1], size=(num_iSst, num_iPV), p=[1-p_nn['Sst_PV'], p_nn['Sst_PV']])\n",
    "    # inhibitory Sst to inhibitory Htr\n",
    "    weight_matrix[num_excitatory+num_iPV:num_excitatory+num_iPV+num_iSst, num_excitatory+num_iPV:num_excitatory+num_iPV+num_iSst] = np.random.choice([0, -1], size=(num_iSst, num_iSst), p=[1-p_nn['Sst_Sst'], p_nn['Sst_Sst']])\n",
    "    # inhibitory Sst to inhibitory Sst\n",
    "    weight_matrix[num_excitatory+num_iPV:num_excitatory+num_iPV+num_iSst, num_excitatory+num_iPV+num_iSst:] = np.random.choice([0, -1], size=(num_iSst, num_iHtr), p=[1-p_nn['Sst_Htr'], p_nn['Sst_Htr']]) \n",
    "\n",
    "    # inhibitory Sst to excitatory\n",
    "    weight_matrix[num_excitatory+num_iPV+num_iSst:, :num_excitatory] = np.random.choice([0, -1], size=(num_iHtr, num_excitatory), p=[1-p_nn['Htr_e'], p_nn['Htr_e']])\n",
    "    # inhibitory Sst to inhibitory PV\n",
    "    weight_matrix[num_excitatory+num_iPV+num_iSst:, num_excitatory:num_excitatory+num_iPV] = np.random.choice([0, -1], size=(num_iHtr, num_iPV), p=[1-p_nn['Htr_PV'], p_nn['Htr_PV']])\n",
    "    # inhibitory Sst to inhibitory Htr\n",
    "    weight_matrix[num_excitatory+num_iPV+num_iSst:, num_excitatory+num_iPV:num_excitatory+num_iPV+num_iSst] = np.random.choice([0, -1], size=(num_iHtr, num_iSst), p=[1-p_nn['Htr_Sst'], p_nn['Htr_Sst']])\n",
    "    # inhibitory Sst to inhibitory Sst\n",
    "    weight_matrix[num_excitatory+num_iPV+num_iSst:, num_excitatory+num_iPV+num_iSst:] = np.random.choice([0, -1], size=(num_iHtr, num_iHtr), p=[1-p_nn['Htr_Htr'], p_nn['Htr_Htr']]) \n",
    "\n",
    "\n",
    "    # Initialize non-zero values using log normal distribution\n",
    "    mu = -0.64\n",
    "    sigma = 0.51\n",
    "    non_zero_indices = np.where(weight_matrix != 0)\n",
    "    weight_matrix[non_zero_indices] = np.random.lognormal(mean=mu, sigma=sigma, size=non_zero_indices[0].shape)\n",
    "\n",
    "    # Multiply the last num_inhibitory rows by -10\n",
    "    weight_matrix[-num_inhibitory:, :] *= -10\n",
    "\n",
    "    return torch.tensor(weight_matrix.astype(np.float32))\n",
    "\n",
    "# leaky integrate-and-fire neuron with recurrent connections from snn torch with refractory period\n",
    "class RLIF1(LIF):\n",
    "    def __init__(\n",
    "        self,\n",
    "        beta,\n",
    "        V=1.0,\n",
    "        all_to_all=True,\n",
    "        linear_features=None,\n",
    "        conv2d_channels=None,\n",
    "        kernel_size=None,\n",
    "        threshold=-55.0,  # Changed threshold to -55 mV\n",
    "        spike_grad=None,\n",
    "        surrogate_disable=False,\n",
    "        init_hidden=False,\n",
    "        inhibition=False,\n",
    "        learn_beta=False,\n",
    "        learn_threshold=False,\n",
    "        learn_recurrent=True,\n",
    "        reset_mechanism='zero',\n",
    "        state_quant=False,\n",
    "        output=False,\n",
    "        reset_delay=True,\n",
    "        refractory_period=5,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            beta,\n",
    "            threshold,\n",
    "            spike_grad,\n",
    "            surrogate_disable,\n",
    "            init_hidden,\n",
    "            inhibition,\n",
    "            learn_beta,\n",
    "            learn_threshold,\n",
    "            reset_mechanism,\n",
    "            state_quant,\n",
    "            output,\n",
    "        )\n",
    "\n",
    "        self.all_to_all = all_to_all\n",
    "        self.learn_recurrent = learn_recurrent\n",
    "\n",
    "        # linear params\n",
    "        self.linear_features = linear_features\n",
    "\n",
    "        # Conv2d params\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv2d_channels = conv2d_channels\n",
    "\n",
    "        # catch cases\n",
    "        self._rleaky_init_cases()\n",
    "\n",
    "        # initialize recurrent connections\n",
    "        if self.all_to_all:\n",
    "            self._init_recurrent_net()\n",
    "        else:\n",
    "            self._V_register_buffer(V, learn_recurrent)\n",
    "            self._init_recurrent_one_to_one()\n",
    "\n",
    "        if not learn_recurrent:\n",
    "            self._disable_recurrent_grad()\n",
    "\n",
    "        self._init_mem()\n",
    "\n",
    "        if self.reset_mechanism_val == 0:\n",
    "            self.state_function = self._base_sub\n",
    "        elif self.reset_mechanism_val == 1:\n",
    "            self.state_function = self._base_zero\n",
    "        elif self.reset_mechanism_val == 2:\n",
    "            self.state_function = self._base_int\n",
    "\n",
    "        self.reset_delay = reset_delay\n",
    "\n",
    "        # Refractory period in timesteps\n",
    "        self.refractory_period = refractory_period\n",
    "\n",
    "    def _init_mem(self):\n",
    "        spk = torch.zeros(0)\n",
    "        mem = torch.zeros(0)\n",
    "        refractory_counter = torch.zeros(0)\n",
    "\n",
    "        self.register_buffer('spk', spk, False)\n",
    "        self.register_buffer('mem', mem, False)\n",
    "        self.register_buffer('refractory_counter', refractory_counter, persistent=False)\n",
    "\n",
    "    def reset_mem(self):\n",
    "        self.spk = torch.zeros_like(self.spk, device=self.spk.device)\n",
    "        # Initialize the membrane potential with a normal distribution (mean=0, std=1)\n",
    "        self.mem = torch.randn_like(self.mem, device=self.mem.device)\n",
    "        self.refractory_counter = torch.zeros_like(self.refractory_counter, device=self.refractory_counter.device)\n",
    "        return self.spk, self.mem\n",
    "\n",
    "    def init_rleaky(self):\n",
    "        return self.reset_mem()\n",
    "\n",
    "    def forward(self, input_, spk=None, mem=None, refractory_counter=None):\n",
    "        if not spk is None:\n",
    "            self.spk = spk\n",
    "\n",
    "        if not mem is None:\n",
    "            self.mem = mem\n",
    "\n",
    "        if not refractory_counter is None:\n",
    "            self.refractory_counter = refractory_counter\n",
    "\n",
    "        if self.init_hidden and (not mem is None or not spk is None or not refractory_counter is None):\n",
    "            raise TypeError(\n",
    "                'When `init_hidden=True`, RLeaky expects 1 input argument.'\n",
    "            )\n",
    "\n",
    "        if not self.spk.shape == input_.shape:\n",
    "            self.spk = torch.zeros_like(input_, device=self.spk.device)\n",
    "\n",
    "        if not self.mem.shape == input_.shape:\n",
    "            self.mem = torch.randn_like(input_, device=self.mem.device)\n",
    "\n",
    "        if not self.refractory_counter.shape == input_.shape:\n",
    "            self.refractory_counter = torch.zeros_like(input_, device=self.refractory_counter.device)\n",
    "\n",
    "        # With each forward, decrement the counter\n",
    "        self.refractory_counter = torch.clamp(self.refractory_counter - 1, min=0)\n",
    "\n",
    "        # Update the membrane potential\n",
    "        self.reset = self.mem_reset(self.mem)\n",
    "        self.mem = self.state_function(input_)\n",
    "\n",
    "        # Set a spike on when refractory period is 0\n",
    "        refractory_mask = (self.refractory_counter == 0)\n",
    "        self.spk = self.fire(self.mem) * refractory_mask\n",
    "\n",
    "        # Update the refractory counter back to 5 where spikes occurred\n",
    "        self.refractory_counter[self.spk > 0] = self.refractory_period\n",
    "\n",
    "        if not self.reset_delay:\n",
    "            do_reset = (\n",
    "                self.spk / self.graded_spikes_factor - self.reset\n",
    "            )\n",
    "            if self.reset_mechanism_val == 0:\n",
    "                self.mem = self.mem - do_reset * self.threshold\n",
    "            elif self.reset_mechanism_val == 1:\n",
    "                self.mem = self.mem - do_reset * self.mem\n",
    "\n",
    "        if self.output:\n",
    "            return self.spk, self.mem\n",
    "        elif self.init_hidden:\n",
    "            return self.spk\n",
    "        else:\n",
    "            return self.spk, self.mem\n",
    "\n",
    "    def _init_recurrent_net(self):\n",
    "        if self.all_to_all:\n",
    "            if self.linear_features:\n",
    "                self._init_recurrent_linear()\n",
    "            elif self.kernel_size is not None:\n",
    "                self._init_recurrent_conv2d()\n",
    "        else:\n",
    "            self._init_recurrent_one_to_one()\n",
    "\n",
    "    def _init_recurrent_linear(self):\n",
    "        self.recurrent = nn.Linear(self.linear_features, self.linear_features)\n",
    "\n",
    "    def _init_recurrent_conv2d(self):\n",
    "        self._init_padding()\n",
    "        self.recurrent = nn.Conv2d(\n",
    "            in_channels=self.conv2d_channels,\n",
    "            out_channels=self.conv2d_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            padding=self.padding,\n",
    "        )\n",
    "\n",
    "    def _init_padding(self):\n",
    "        if type(self.kernel_size) is int:\n",
    "            self.padding = self.kernel_size // 2, self.kernel_size // 2\n",
    "        else:\n",
    "            self.padding = self.kernel_size[0] // 2, self.kernel_size[1] // 2\n",
    "\n",
    "    def _init_recurrent_one_to_one(self):\n",
    "        self.recurrent = RecurrentOneToOne(self.V)\n",
    "\n",
    "    def _disable_recurrent_grad(self):\n",
    "        for param in self.recurrent.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def _base_state_function(self, input_):\n",
    "        # Adjusting beta to decay towards -70 mV\n",
    "        base_fn = (\n",
    "            self.beta.clamp(0, 1) * (self.mem + 70) + input_ + self.recurrent(self.spk) - 70\n",
    "        )\n",
    "        return base_fn\n",
    "\n",
    "    def _base_sub(self, input_):\n",
    "        return self._base_state_function(input_) - self.reset * self.threshold\n",
    "\n",
    "    def _base_zero(self, input_):\n",
    "        return self._base_state_function(input_) - self.reset * self._base_state_function(input_)\n",
    "\n",
    "    def _base_int(self, input_):\n",
    "        return self._base_state_function(input_)\n",
    "\n",
    "    def _rleaky_init_cases(self):\n",
    "        all_to_all_bool = bool(self.all_to_all)\n",
    "        linear_features_bool = self.linear_features\n",
    "        conv2d_channels_bool = bool(self.conv2d_channels)\n",
    "        kernel_size_bool = bool(self.kernel_size)\n",
    "\n",
    "        if all_to_all_bool:\n",
    "            if not (linear_features_bool):\n",
    "                if not (conv2d_channels_bool or kernel_size_bool):\n",
    "                    raise TypeError(\n",
    "                        'When `all_to_all=True`, RLeaky requires either'\n",
    "                        '`linear_features` or (`conv2d_channels` and '\n",
    "                        '`kernel_size`) to be specified. The '\n",
    "                        'shape should match the shape of the output spike of '\n",
    "                        'the layer.'\n",
    "                    )\n",
    "                elif conv2d_channels_bool ^ kernel_size_bool:\n",
    "                    raise TypeError(\n",
    "                        '`conv2d_channels` and `kernel_size` must both be'\n",
    "                        'specified. The shape of `conv2d_channels` should '\n",
    "                        'match the shape of the output'\n",
    "                        'spikes.'\n",
    "                    )\n",
    "            elif (linear_features_bool and kernel_size_bool) or (\n",
    "                linear_features_bool and conv2d_channels_bool\n",
    "            ):\n",
    "                raise TypeError(\n",
    "                    '`linear_features` cannot be specified at the same time as'\n",
    "                    '`conv2d_channels` or `kernel_size`. A linear layer and '\n",
    "                    'conv2d layer cannot both'\n",
    "                    'be specified at the same time.'\n",
    "                )\n",
    "        else:\n",
    "            if (\n",
    "                linear_features_bool\n",
    "                or conv2d_channels_bool\n",
    "                or kernel_size_bool\n",
    "            ):\n",
    "                raise TypeError(\n",
    "                    'When `all_to_all`=False, none of `linear_features`,'\n",
    "                    '`conv2d_channels`, or `kernel_size` should be specified. '\n",
    "                    'The weight `V` is used'\n",
    "                    'instead.'\n",
    "                )\n",
    "\n",
    "    @classmethod\n",
    "    def detach_hidden(cls):\n",
    "        for layer in range(len(cls.instances)):\n",
    "            if isinstance(cls.instances[layer], RLIF1):\n",
    "                cls.instances[layer].mem.detach_()\n",
    "                cls.instances[layer].spk.detach_()\n",
    "\n",
    "    @classmethod\n",
    "    def reset_hidden(cls):\n",
    "        for layer in range(len(cls.instances)):\n",
    "            if isinstance(cls.instances[layer], RLIF1):\n",
    "                (\n",
    "                    cls.instances[layer].spk,\n",
    "                    cls.instances[layer].mem,\n",
    "                ) = cls.instances\n",
    "\n",
    "\n",
    "### Defining the Network\n",
    "\n",
    "# RSNN model with 1 input neurons, 200 hidden neurons, and 1 output neuron, with 3 inhibitory neuron classes\n",
    "class RSNN2(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super(RSNN2, self).__init__()\n",
    "        num_inputs = num_inputs\n",
    "        num_hidden = num_hidden\n",
    "        num_output = num_outputs\n",
    "        pe_e = 0.16\n",
    "\n",
    "        # Dictionary with probabilities of connection between each neuron type \n",
    "        p_nn = {'e_e': 0.16, 'e_PV': 0.395, 'e_Sst': 0.182, 'e_Htr': 0.105,\n",
    "                'PV_e': 0.411, 'PV_PV': 0.451, 'PV_Sst': 0.03, 'PV_Htr': 0.22,\n",
    "                'Sst_e': 0.424, 'Sst_PV': 0.857, 'Sst_Sst': 0.082, 'Sst_Htr': 0.77,\n",
    "                'Htr_e': 0.087, 'Htr_PV': 0.02, 'Htr_Sst': 0.0625, 'Htr_Htr': 0.028\n",
    "                } \n",
    "\n",
    "        self.p_nn = p_nn\n",
    "        \n",
    "        # Define the dimensions\n",
    "        num_excitatory = round(0.85 * num_hidden) # 85% : 15% Excitatory to inhibitory\n",
    "        self.num_excitatory = num_excitatory\n",
    "        num_inhibitory = num_hidden - num_excitatory\n",
    "\n",
    "        # Three inhibitory neuron classes: 40% PV, 30% Sst, 30% Ht3aR\n",
    "        num_iPV = round(0.4 * num_inhibitory)\n",
    "        self.num_iPV = num_iPV\n",
    "        num_iSst = round(0.3 * num_inhibitory)\n",
    "        self.num_iSst = num_iSst\n",
    "        num_iHtr = num_inhibitory - num_iSst - num_iPV\n",
    "        self.num_iHtr = num_iHtr\n",
    "\n",
    "        # Three beta values for E, PV, Sst, and Htr3aR\n",
    "        # Values chosen based on spike triggered adaptation behavior of each class\n",
    "        beta_e = torch.asarray([0.85] * num_excitatory)\n",
    "        beta_iPV = torch.asarray([0.7] * num_iPV)   # Little/ no spike frequency adaptation \n",
    "        beta_iHtr = torch.asarray([0.6] * num_iHtr)    # Mostly adapting\n",
    "        beta_iSst = torch.asarray([0.3] * num_iSst)  # Spike frequency adaptation\n",
    "        beta = torch.cat((beta_e, beta_iPV, beta_iSst, beta_iHtr)) # create array of betas corresponding to each neuron!\n",
    "\n",
    "        self.false_neg = []\n",
    "        self.false_pos = []\n",
    "\n",
    "        #input to hidden layer\n",
    "        input_hid_mx = conn_mx(num_inputs, num_hidden, pe_e)\n",
    "        self.input_hid_mx = input_hid_mx\n",
    "        self.l1 = nn.Linear(num_inputs,num_hidden)\n",
    "        self.l1.weight.data = input_hid_mx.T\n",
    "\n",
    "        # Recurrent layer weight matrix\n",
    "        hidden_mx = hid_mx(num_excitatory, num_inhibitory, num_iPV, num_iSst, num_iHtr, p_nn) \n",
    "        self.rlif1 = RLIF1(reset_mechanism='zero', threshold = 1, beta=beta, linear_features=num_hidden, all_to_all=True)\n",
    "        self.rlif1.recurrent.weight.data = hidden_mx.T\n",
    "\n",
    "        #hidden to output layer\n",
    "        # For the purposes of our game, this is pretty much completely unnecessary and can be replaced w a single output neuron\n",
    "        hid_out_mx = conn_mx(num_hidden,num_output,pe_e)\n",
    "        self.l2 = nn.Linear(num_hidden, num_output)\n",
    "        self.l2.weight.data = hid_out_mx.T \n",
    "\n",
    "        self.spk1,self.mem1 = self.rlif1.init_rleaky()\n",
    "        self.spk1_rec = []\n",
    "        self.cur2_rec = []\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ## WHAT SHOULD HAPPEN: Preserves state from previous forward to include as input (self.spk1, self.mem1)\n",
    "        ### Resets current output & spikes so we can see them at each time step\n",
    "\n",
    "\n",
    "        # spk1,mem1 = self.rlif1.init_rleaky()\n",
    "        self.spk1_rec = []\n",
    "        self.cur2_rec = []\n",
    "\n",
    "        # print(inputs.shape)\n",
    "        for step in range(inputs.shape[0]):\n",
    "            cur_input = inputs[step,:]\n",
    "            cur1 = self.l1(cur_input)\n",
    "            self.spk1,self.mem1 = self.rlif1(cur1, self.spk1, self.mem1)\n",
    "            # self.mem1 = self.mem1\n",
    "            # cur2 = self.l2(self.spk1)\n",
    "\n",
    "            self.spk1_rec.append(self.spk1)\n",
    "            # self.cur2_rec.append(cur2)\n",
    "\n",
    "        self.spk1_rec = torch.stack(self.spk1_rec)\n",
    "        # self.cur2_rec = torch.stack(self.cur2_rec)\n",
    "        \n",
    "        return self.cur2_rec, self.spk1_rec\n",
    "\n",
    "    def positive_negative_weights(self):\n",
    "\n",
    "        excitatory_weights = self.rlif1.recurrent.weight.data[:, :self.num_excitatory]\n",
    "        inhibitory_weights = self.rlif1.recurrent.weight.data[:, self.num_excitatory:]\n",
    "\n",
    "        #save the number of positives in inhibitory and negatives in excitatory region\n",
    "        num_false_neg = torch.sum(excitatory_weights < 0).item()\n",
    "        num_false_pos = torch.sum(inhibitory_weights > 0).item()\n",
    "\n",
    "        self.false_neg.append(num_false_neg)\n",
    "        self.false_pos.append(num_false_pos)\n",
    "\n",
    "        # Clamp switched sign values at 0\n",
    "        excitatory_weights.clamp_(min=0)\n",
    "        inhibitory_weights.clamp_(max=0)\n",
    "\n",
    "        mu = -0.64\n",
    "        sigma = 0.51\n",
    "\n",
    "\n",
    "        #change the code so that for any vanishing excitatory neuron, populate another excitatory.\n",
    "\n",
    "        #following code picks random indices from excitatory and inhibitory originating weights\n",
    "        #for the number of num_false_neg and num_false_neg for inhibitory and excitatory originating weights respectively\n",
    "        #assigns them with the lognormal dist\n",
    "        excitatory_zero_indices = (self.rlif1.recurrent.weight.data[:, :self.num_excitatory] == 0).nonzero(as_tuple=True)\n",
    "        inhibitory_zero_indices = (self.rlif1.recurrent.weight.data[:, self.num_excitatory:] == 0).nonzero(as_tuple=True)\n",
    "\n",
    "        if (len(excitatory_zero_indices) > num_false_pos):\n",
    "            excitatory_sampled_indices = torch.stack([\n",
    "                    excitatory_zero_indices[0][torch.randint(len(excitatory_zero_indices[0]), (num_false_pos,))],\n",
    "                    excitatory_zero_indices[1][torch.randint(len(excitatory_zero_indices[1]), (num_false_pos,))]\n",
    "                ], dim=1)\n",
    "\n",
    "            # generating self.excitatory_changes number of lognormal values\n",
    "            new_excitatory_values = torch.from_numpy(np.random.lognormal(mean=mu, sigma=sigma, size=num_false_pos)).float()\n",
    "            self.rlif1.recurrent.weight.data[excitatory_sampled_indices[:, 0], excitatory_sampled_indices[:, 1]] = new_excitatory_values\n",
    "\n",
    "        if (len(inhibitory_zero_indices) > num_false_neg):\n",
    "            inhibitory_sampled_indices = torch.stack([\n",
    "                    inhibitory_zero_indices[0][torch.randint(len(inhibitory_zero_indices[0]), (num_false_neg,))],\n",
    "                    inhibitory_zero_indices[1][torch.randint(len(inhibitory_zero_indices[1]), (num_false_neg,))]\n",
    "                ], dim=1)\n",
    "\n",
    "            new_inhibitory_values = -torch.from_numpy(np.random.lognormal(mean=mu, sigma=sigma, size=num_false_neg)).float()\n",
    "            self.rlif1.recurrent.weight.data[inhibitory_sampled_indices[:, 0], self.num_excitatory + inhibitory_sampled_indices[:, 1]] = new_inhibitory_values\n",
    "\n",
    "# custom loss function with MSE loss, firing rate loss, criticality loss, and synchrony loss\n",
    "class CustomLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, target_synchrony=1.4, target_firing_rate=0.02, target_branching=1.0,batch_size=25):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        if batch_size == 1:\n",
    "            self.target_synchrony = torch.tensor(target_synchrony, requires_grad=True)\n",
    "            self.target_firing_rate = torch.tensor(target_firing_rate,requires_grad=True)\n",
    "            self.target_branching = torch.tensor(target_branching,requires_grad=True)\n",
    "        else:\n",
    "            self.target_synchrony = torch.tensor([target_synchrony] * batch_size, requires_grad=True)\n",
    "            self.target_firing_rate = torch.tensor([target_firing_rate] * batch_size,requires_grad=True)\n",
    "            self.target_branching = torch.tensor([target_branching] * batch_size,requires_grad=True)\n",
    "\n",
    "\n",
    "    def forward(self, firing_rate):\n",
    "\n",
    "        # choice = (sum(outputs[0]) >= 15) # Simple threshold of 15 for a jump. No clue if this is good, will need to be tweaked\n",
    "        # success = game(index, choice) # need to: make the game function (probably as an iterable or smth)\n",
    "\n",
    "        # w_crit = 0\n",
    "        w_rate = 1\n",
    "        # w_sync = 0\n",
    "        # w_choice = 1\n",
    "        \n",
    "        # choice_loss = 1000 * (not success) - index # index is time, so this should reward lasting longer... not sure though\n",
    "        rate_loss = nn.MSELoss()(firing_rate, self.target_firing_rate)\n",
    "        # criticality_loss = nn.MSELoss()(criticality,self.target_branching)\n",
    "        # synchrony_loss = nn.MSELoss()(synchrony_fano_factor,self.target_synchrony)\n",
    "\n",
    "        # self.choice_loss = choice_loss\n",
    "        self.rate_loss = rate_loss\n",
    "        # self.criticality_loss = criticality_loss\n",
    "        # self.synchrony_loss = synchrony_loss\n",
    "\n",
    "        total_loss = w_rate*rate_loss # + w_choice*choice_loss + w_sync*synchrony_loss + w_crit*criticality_loss\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "### Evolution\n",
    "# Genetic Encoding and Decoding\n",
    "\n",
    "# converts model to gene format by concatenating all the parameters\n",
    "def encode_model(model):\n",
    "    gene = []\n",
    "    for param in model.parameters():\n",
    "        gene.append(param.data.cpu().numpy().flatten())\n",
    "    gene = np.concatenate(gene)\n",
    "    return gene\n",
    "\n",
    "# decodes gene to model format by reshaping the gene to the original parameter shapes\n",
    "def decode_model(model, gene):\n",
    "    current_index = 0\n",
    "    new_model = deepcopy(model)\n",
    "    for param in new_model.parameters():\n",
    "        param_shape = param.data.cpu().numpy().shape\n",
    "        param_size = np.prod(param_shape)\n",
    "        param.data = torch.tensor(gene[current_index:current_index + param_size].reshape(param_shape))\n",
    "        current_index += param_size\n",
    "    return new_model\n",
    "\n",
    "# Main Evolution Class\n",
    "class Evolution(object):\n",
    "    def __init__(self, model_class, model_args, model_kwargs):\n",
    "        # Initialize the model class and its arguments\n",
    "        self.model_class = model_class\n",
    "        self.model_args = model_args\n",
    "        self.model_kwargs = model_kwargs\n",
    "\n",
    "    # initialize first population of models \n",
    "    def populate(self, n_models):\n",
    "        models = []\n",
    "        for _ in range(n_models):\n",
    "            model = self.model_class(*self.model_args, **self.model_kwargs)\n",
    "            self.initialize_weights(model)\n",
    "            # Freeze the weights\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            models.append(model)\n",
    "        return models\n",
    "\n",
    "    # initialize weights of the model with specified three inhibitory neuron classes\n",
    "    def initialize_weights(self, model):\n",
    "        num_excitatory = model.num_excitatory\n",
    "        num_hidden = model.l1.out_features\n",
    "        num_iPV = model.num_iPV\n",
    "        num_iSst = model.num_iSst\n",
    "        num_iHtr = model.num_iHtr\n",
    "        num_inputs = model.l1.in_features\n",
    "        num_output = model.l2.out_features\n",
    "        p_nn = model.p_nn\n",
    "        num_inhibitory = num_hidden - num_excitatory\n",
    "        pe_e = 0.16\n",
    "\n",
    "        # Initialize the input to hidden layer weights\n",
    "        input_hid_mx = conn_mx(num_inputs, num_hidden, pe_e)\n",
    "        model.l1.weight.data = input_hid_mx.T\n",
    "\n",
    "        # Initialize the recurrent layer weights\n",
    "        hidden_mx = hid_mx(num_excitatory, num_inhibitory, num_iPV, num_iSst, num_iHtr, p_nn)\n",
    "        model.rlif1.recurrent.weight.data = hidden_mx.T\n",
    "\n",
    "        # Initialize the hidden to output layer weights\n",
    "        hid_out_mx = conn_mx(num_hidden, num_output, pe_e)\n",
    "        model.l2.weight.data = hid_out_mx.T\n",
    "\n",
    "        # Store the initial sparsity mask\n",
    "        self.weights = model.rlif1.recurrent.weight.data\n",
    "        self.sparse_mask = torch.where(self.weights == 0, 1, 0)\n",
    " \n",
    "    # encode the population of models to gene representation\n",
    "    def encode_population(self, models):\n",
    "        return [encode_model(model) for model in models]\n",
    "    \n",
    "    # decode the gene representation to model representation\n",
    "    def decode_population(self, genes, template_model):\n",
    "        return [decode_model(template_model, gene) for gene in genes]\n",
    "\n",
    "    ### TODO: TEST OF MULTIPROCESSING\n",
    "    def evaluate(self, models, game_class, game_args):\n",
    "        fitness = [0 for _ in range(len(models))]\n",
    "        processes = []\n",
    "        q = mp.Queue()\n",
    "        for i, model in enumerate(models):\n",
    "            processes.append(mp.Process(target=self.queue_eval_model, args=(q, i, model, game_class, game_args)))\n",
    "            processes[i].start()\n",
    "\n",
    "        for i in range(len(models)):\n",
    "            id, loss = q.get()\n",
    "            fitness[id] = loss\n",
    "\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "        return fitness\n",
    "\n",
    "    def queue_eval_model(self, q, id, model, game_class, game_args):\n",
    "        loss = self.evaluate_model(model, game_class, game_args)\n",
    "        q.put((id, loss))\n",
    "        return\n",
    "\n",
    "    # evaluate a model with the dinosaur dataloader\n",
    "    # TODO: This can be multiprocessed\n",
    "    def evaluate_model(self, model, game_class, game_args):\n",
    "        criterion = CustomLoss(target_firing_rate=0.02, batch_size=1)\n",
    "        running_loss = 0\n",
    "        game = game_class(*game_args)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Run the game. Running loss will have the score included in it, so the criterion function does not need to consider the game at all\n",
    "            while game.alive:\n",
    "                inputs = torch.tensor([[game.get_input(),]], dtype=torch.float)\n",
    "                outputs, spikes = model(inputs)\n",
    "                firing_rate = torch.sum(spikes) / torch.tensor(spikes.numel(), dtype=torch.float)\n",
    "                loss = criterion(firing_rate)\n",
    "                running_loss -= loss.item()\n",
    "\n",
    "                # choice = int((sum(outputs) >= 1)) # 0.05\n",
    "                choice = spikes[0,0]\n",
    "                # Punish jumps\n",
    "                # running_loss += 0.2 * choice\n",
    "                # print(f'Outs: {outputs}, sum: {sum(outputs)}')\n",
    "                game.step(choice)\n",
    "            \n",
    "            # Reward a good score...\n",
    "            running_loss += game.score # Should be +=?\n",
    "\n",
    "        return running_loss\n",
    "\n",
    "    # select the top k models based on fitness\n",
    "    def select(self, genes, fitness, k=2):\n",
    "        selected_indices = np.flip(np.argsort(fitness))[:k]\n",
    "        # print(f'Argsort: {np.argsort(fitness)} Selected: {selected_indices}')\n",
    "        return [genes[i] for i in selected_indices], [fitness[i] for i in selected_indices]\n",
    "\n",
    "    # crossover two parents to generate a child\n",
    "    def crossover(self, parent1, parent2):\n",
    "        child = deepcopy(parent1)\n",
    "        crossover_mask = np.random.rand(len(child)) < 0.5\n",
    "        child[crossover_mask] = parent2[crossover_mask]\n",
    "        return child\n",
    "\n",
    "    # mutate the gene with a mutation rate\n",
    "    def mutate(self, gene, mutation_rate):\n",
    "        mutation_mask = np.random.rand(len(gene)) < mutation_rate\n",
    "        gene[mutation_mask] += np.random.randn(np.sum(mutation_mask))\n",
    "\n",
    "        # Decode the gene to model format\n",
    "        model = self.model_class(*self.model_args, **self.model_kwargs)\n",
    "        decode_model(model, gene)  \n",
    "\n",
    "        # Reapply the initial sparsity mask\n",
    "        model_weights = model.rlif1.recurrent.weight.data\n",
    "        model_weights[self.sparse_mask == True] = 0\n",
    "\n",
    "        # Split the weights into excitatory and inhibitory\n",
    "        excitatory_weights = model_weights[:, :model.num_excitatory]\n",
    "        inhibitory_weights = model_weights[:, model.num_excitatory:]\n",
    "\n",
    "        # Clamp switched sign values at 0\n",
    "        excitatory_weights.clamp_(min=0)\n",
    "        inhibitory_weights.clamp_(max=0)\n",
    "\n",
    "        # Ensure no neuron vanishes to enforce dale's law\n",
    "        self.handle_vanishing_neurons(model, excitatory_weights, inhibitory_weights)  # Assuming handle_vanishing_neurons is a method of the class\n",
    "\n",
    "        return gene\n",
    "    \n",
    "    # dale's law implementation to ensure no neuron vanishes\n",
    "    def handle_vanishing_neurons(self, model, excitatory_weights, inhibitory_weights):\n",
    "        num_excitatory = model.num_excitatory\n",
    "\n",
    "        mu = -0.64\n",
    "        sigma = 0.51\n",
    "\n",
    "        num_false_neg = torch.sum(excitatory_weights < 0).item()\n",
    "        num_false_pos = torch.sum(inhibitory_weights > 0).item()\n",
    "\n",
    "        excitatory_zero_indices = (model.rlif1.recurrent.weight.data[:, :num_excitatory] == 0).nonzero(as_tuple=True)\n",
    "        inhibitory_zero_indices = (model.rlif1.recurrent.weight.data[:, num_excitatory:] == 0).nonzero(as_tuple=True)\n",
    "\n",
    "        if len(excitatory_zero_indices[0]) > num_false_pos:\n",
    "            excitatory_sampled_indices = torch.stack([\n",
    "                excitatory_zero_indices[0][torch.randint(len(excitatory_zero_indices[0]), (num_false_pos,))],\n",
    "                excitatory_zero_indices[1][torch.randint(len(excitatory_zero_indices[1]), (num_false_pos,))]\n",
    "            ], dim=1)\n",
    "\n",
    "            new_excitatory_values = torch.from_numpy(np.random.lognormal(mean=mu, sigma=sigma, size=num_false_pos)).float().to(model.rlif1.recurrent.weight.data.device)\n",
    "            model.rlif1.recurrent.weight.data[excitatory_sampled_indices[:, 0], excitatory_sampled_indices[:, 1]] = new_excitatory_values\n",
    "\n",
    "        if len(inhibitory_zero_indices[0]) > num_false_neg:\n",
    "            inhibitory_sampled_indices = torch.stack([\n",
    "                inhibitory_zero_indices[0][torch.randint(len(inhibitory_zero_indices[0]), (num_false_neg,))],\n",
    "                inhibitory_zero_indices[1][torch.randint(len(inhibitory_zero_indices[1]), (num_false_neg,))]\n",
    "            ], dim=1)\n",
    "\n",
    "            new_inhibitory_values = -torch.from_numpy(np.random.lognormal(mean=mu, sigma=sigma, size=num_false_neg)).float().to(model.rlif1.recurrent.weight.data.device)\n",
    "            model.rlif1.recurrent.weight.data[inhibitory_sampled_indices[:, 0], num_excitatory + inhibitory_sampled_indices[:, 1]] = new_inhibitory_values\n",
    "\n",
    "\n",
    "    # generate next population of offspring from parents\n",
    "    def generate_offspring(self, parents, n_offspring, mutation_rate):\n",
    "        offspring = []\n",
    "        for _ in range(n_offspring):\n",
    "            parent1, parent2 = random.sample(parents, 2)\n",
    "            child = self.crossover(parent1, parent2)\n",
    "            child = self.mutate(child, mutation_rate)\n",
    "            offspring.append(child)\n",
    "        return offspring\n",
    "\n",
    "    # plot the best fitness model across generations\n",
    "    def plot_best_fitness(self, all_best_fitness):\n",
    "        plt.figure()\n",
    "        plt.plot(all_best_fitness)\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Best Fitness (Loss)')\n",
    "        plt.title('Evolution of Best Fitness')\n",
    "        plt.savefig(f'Best_Fitness {time.asctime()}.png')\n",
    "\n",
    "    # plot the fitness distribution across generations\n",
    "    def plot_fitness_distribution(self, all_fitness):\n",
    "        plt.figure()\n",
    "        num_generations = len(all_fitness)\n",
    "        cmap = plt.get_cmap('viridis', num_generations)  # Use the viridis colormap\n",
    "\n",
    "        for i, fitness in enumerate(all_fitness):\n",
    "            plt.hist(fitness, bins=30, alpha=0.5, label=f'Gen {i+1}', color=cmap(i / num_generations))\n",
    "\n",
    "        norm = plt.Normalize(vmin=1, vmax=num_generations)\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "\n",
    "        cbar = plt.colorbar(sm, ax=plt.gca(), ticks=np.linspace(1, num_generations, num_generations))\n",
    "        cbar.set_label('Generation')\n",
    "\n",
    "        plt.xlabel('Fitness (Loss)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Fitness Distribution Across Generations')\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "        plt.savefig(f'Fitness_Distr {time.asctime()}.png')\n",
    "\n",
    "    # plot the average fitness across generations\n",
    "    def plot_average_fitness(self, all_fitness):\n",
    "        average_fitness = [np.mean(fitness) for fitness in all_fitness]\n",
    "        plt.figure()\n",
    "        plt.plot(average_fitness)\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Average Fitness (Loss)')\n",
    "        plt.title('Evolution of Average Fitness')\n",
    "        plt.savefig(f'Average_Fitness {time.asctime()}.png')\n",
    "\n",
    "    # run the evolutionary process\n",
    "    def evolve(self, n_models, n_offspring, n_generations, game_class, game_args, mutation_rate):\n",
    "        template_model = self.model_class(*self.model_args, **self.model_kwargs)\n",
    "        \n",
    "        # intialize first population of models\n",
    "        models = self.populate(n_models)\n",
    "        genes = self.encode_population(models)\n",
    "        all_best_fitness = []\n",
    "        all_fitness = []\n",
    "        best_gene_overall = None\n",
    "        # best_fitness_overall = float('inf')\n",
    "        best_fitness_overall = 0\n",
    "        \n",
    "        # run the evolution process for n_generations\n",
    "        for i in range(n_generations):\n",
    "            models = self.decode_population(genes, template_model)\n",
    "            fitness = self.evaluate(models, game_class, game_args)\n",
    "            all_fitness.append(fitness)\n",
    "            parents, parent_fitness = self.select(genes, fitness)\n",
    "            offspring = self.generate_offspring(parents, n_offspring, mutation_rate)\n",
    "            genes = parents + offspring\n",
    "            best_fitness = min(parent_fitness)\n",
    "            all_best_fitness.append(best_fitness)\n",
    "\n",
    "            if best_fitness > best_fitness_overall:\n",
    "                best_fitness_overall = best_fitness\n",
    "                best_gene_overall = deepcopy(parents[0])\n",
    "                \n",
    "            print(f'Generation {i+1}/{n_generations}, Best Fitness: {best_fitness}')\n",
    "            print(f'Overall Best Fitness: {best_fitness_overall}')\n",
    "\n",
    "        self.plot_best_fitness(all_best_fitness)\n",
    "        self.plot_average_fitness(all_fitness)\n",
    "        self.plot_fitness_distribution(all_fitness)\n",
    "\n",
    "        best_model = self.decode_population([best_gene_overall], template_model)[0]\n",
    "        final_population = self.decode_population(genes, template_model)\n",
    "\n",
    "        # np.savez_compressed('evolution_data.npz',\n",
    "        #                     all_genes=all_genes,\n",
    "        #                     all_best_fitness=all_best_fitness,\n",
    "        #                     all_fitness=all_fitness,\n",
    "        #                     best_gene_overall=best_gene_overall,\n",
    "        #                     best_fitness_overall=best_fitness_overall\n",
    "        #                     initial_models=initial_models\n",
    "        #                     final_population=final_population\n",
    "        #                     best_model=best_model)\n",
    "        \n",
    "        return best_model, all_best_fitness, final_population\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Plotting\n",
    "# Generates raster plot of the spiking activity of the model\n",
    "def plot_spike_tensor(spk_tensor, title):\n",
    "    # Generate the plot\n",
    "    spk_tensor = spk_tensor.T\n",
    "    fig, axs = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Plot spikes\n",
    "    splt.raster(spk_tensor, axs, s=0.5, c='black')  # Transpose to align with neurons on y-axis\n",
    "\n",
    "    # Set labels and title\n",
    "    axs.set_xlabel('Timestep')\n",
    "    axs.set_ylabel('Neuron')\n",
    "    axs.set_title(title)\n",
    "\n",
    "    plt.savefig(f'Spikes {time.asctime()}.png')\n",
    "\n",
    "\n",
    "\n",
    "# generates heatmaps to capture the connectivity changes between the initial and final models\n",
    "def plot_connectivity_changes_heat(initial_models, final_models):\n",
    "    # Get average weights for initial and final models\n",
    "    initial_avg_weights = get_layer_weights(initial_models)\n",
    "    final_avg_weights = get_layer_weights(final_models)\n",
    "\n",
    "    # Compute the differences\n",
    "    weight_diffs = {\n",
    "        'input_recurrent': final_avg_weights['input_recurrent'] - initial_avg_weights['input_recurrent'],\n",
    "        'recurrent': final_avg_weights['recurrent'] - initial_avg_weights['recurrent'],\n",
    "        'recurrent_output': final_avg_weights['recurrent_output'] - initial_avg_weights['recurrent_output']\n",
    "    }\n",
    "\n",
    "    # Plot heatmaps for each layer\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "    \n",
    "    sns.heatmap(weight_diffs['input_recurrent'], ax=axs[0], cmap='seismic', center=0 )\n",
    "    axs[0].set_title('Difference in Input to Recurrent Weights')\n",
    "    \n",
    "    sns.heatmap(weight_diffs['recurrent'], ax=axs[1], cmap='seismic', center=0)\n",
    "    axs[1].set_title('Difference in Recurrent Weights')\n",
    "    \n",
    "    sns.heatmap(weight_diffs['recurrent_output'], ax=axs[2], cmap='seismic', center=0)\n",
    "    axs[2].set_title('Difference in Recurrent to Output Weights')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Weights {time.asctime()}.png')\n",
    "\n",
    "def get_layer_weights(models):\n",
    "    layer_weights = {\n",
    "        'input_recurrent': [],\n",
    "        'recurrent': [],\n",
    "        'recurrent_output': []\n",
    "    }\n",
    "    \n",
    "    for model in models:\n",
    "        input_recurrent_weights = model.l1.weight.data.cpu().numpy()\n",
    "        recurrent_weights = model.rlif1.recurrent.weight.data.cpu().numpy()\n",
    "        recurrent_output_weights = model.l2.weight.data.cpu().numpy()\n",
    "        \n",
    "        layer_weights['input_recurrent'].append(input_recurrent_weights)\n",
    "        layer_weights['recurrent'].append(recurrent_weights)\n",
    "        layer_weights['recurrent_output'].append(recurrent_output_weights)\n",
    "    \n",
    "    avg_weights = {\n",
    "        'input_recurrent': np.mean(layer_weights['input_recurrent'], axis=0),\n",
    "        'recurrent': np.mean(layer_weights['recurrent'], axis=0),\n",
    "        'recurrent_output': np.mean(layer_weights['recurrent_output'], axis=0)\n",
    "    }\n",
    "    \n",
    "    return avg_weights\n",
    "\n",
    "# generates line plots to capture the connectivity changes between the initial and final models\n",
    "def plot_connectivity_changes_line(initial_models, final_models):\n",
    "    # Get average weights for initial and final models\n",
    "    initial_avg_weights = get_layer_weights(initial_models)\n",
    "    final_avg_weights = get_layer_weights(final_models)\n",
    "\n",
    "    # Compute the differences\n",
    "    weight_diffs = {\n",
    "        'input_recurrent': final_avg_weights['input_recurrent'] - initial_avg_weights['input_recurrent'],\n",
    "        'recurrent': final_avg_weights['recurrent'] - initial_avg_weights['recurrent'],\n",
    "        'recurrent_output': final_avg_weights['recurrent_output'] - initial_avg_weights['recurrent_output']\n",
    "    }\n",
    "\n",
    "    # Plot the differences for each layer\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(15, 15))\n",
    "    \n",
    "    # Input to recurrent layer weights differences\n",
    "    axs[0].plot(weight_diffs['input_recurrent'].flatten(), label='Weight Differences')\n",
    "    axs[0].set_title('Difference in Input to Recurrent Weights')\n",
    "    axs[0].set_xlabel('Weight Index')\n",
    "    axs[0].set_ylabel('Weight Difference')\n",
    "    axs[0].legend()\n",
    "    \n",
    "    # Recurrent layer weights differences\n",
    "    axs[1].plot(weight_diffs['recurrent'].flatten(), label='Weight Differences')\n",
    "    axs[1].set_title('Difference in Recurrent Weights')\n",
    "    axs[1].set_xlabel('Weight Index')\n",
    "    axs[1].set_ylabel('Weight Difference')\n",
    "    axs[1].legend()\n",
    "    \n",
    "    # Recurrent to output layer weights differences\n",
    "    axs[2].plot(weight_diffs['recurrent_output'].flatten(), label='Weight Differences')\n",
    "    axs[2].set_title('Difference in Recurrent to Output Weights')\n",
    "    axs[2].set_xlabel('Weight Index')\n",
    "    axs[2].set_ylabel('Weight Difference')\n",
    "    axs[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Connectivity_Changes {time.asctime()}.png')\n",
    "\n",
    "# rasters for best model of evolution and sine wave predictions\n",
    "def print_model_performance(model, game_class, game_args):\n",
    "\n",
    "        game = game_class(*game_args)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Run the game\n",
    "            while game.alive:\n",
    "                inputs = torch.tensor([[game.get_input(),]], dtype=torch.float)\n",
    "                outputs, spikes = model(inputs)\n",
    "\n",
    "                choice = (sum(outputs) >= 0.05)\n",
    "                game.step(choice)\n",
    "            \n",
    "            # Print the score\n",
    "            print(game.score) \n",
    "\n",
    "        # plot_spike_tensor(spikes, title='Spike Trains')\n",
    "\n",
    "\n",
    "\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "    #         outputs, spikes = model(inputs)\n",
    "            \n",
    "    #         for i in range(min(10, len(targets))):  # Visualize up to 10 samples\n",
    "    #             target = targets[i].cpu().numpy()\n",
    "    #             output = outputs[i].cpu().numpy()\n",
    "\n",
    "    #             x_target = np.arange(len(target))\n",
    "    #             x_output = np.arange(len(output))\n",
    "\n",
    "    #             plt.plot(x_target, target, label=f'Target {i+1}', alpha=0.6)\n",
    "    #             plt.plot(x_output, output, label=f'Output {i+1}', alpha=0.6)\n",
    "\n",
    "    #             plt.xlabel('Index')\n",
    "    #             plt.ylabel('Value')\n",
    "    #             plt.title('Model Performance')\n",
    "    #             plt.legend()\n",
    "    #             plt.grid(True)\n",
    "    #             plt.show()\n",
    "\n",
    "    #         break  # Only plot for the first batch\n",
    "    # plot_spike_tensor(spikes, title='Spike Trains')\n",
    "\n",
    "def visualize_model(model, game_class, game_args):\n",
    "    # Initialize Pygame\n",
    "    pygame.init()\n",
    "    # Screen dimensions\n",
    "    global WIDTH, HEIGHT, font\n",
    "    WIDTH, HEIGHT = 800, 400\n",
    "    screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "    pygame.display.set_caption(\"Dino Game\")\n",
    "    font = pygame.font.Font(None, 36)\n",
    "\n",
    "    game = game_class(*game_args)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Run the game\n",
    "        while game.alive:\n",
    "            start = time.time()\n",
    "\n",
    "            inputs = torch.tensor([[game.get_input(),]], dtype=torch.float)\n",
    "            outputs, spikes = model(inputs)\n",
    "\n",
    "            choice = (sum(outputs) >= 0.05)\n",
    "            game.step(choice)\n",
    "\n",
    "            # Visualize\n",
    "            screen.fill((255, 255, 255))\n",
    "            game.visualize(screen)\n",
    "            # Update display\n",
    "            pygame.display.flip()\n",
    "            rest = time.time() - start\n",
    "            if rest > 0:\n",
    "                time.sleep(rest)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d31894ce-942c-4cf2-8d82-e52ed7830659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  \n",
    "# Perhaps turn this into a dataset\n",
    "class DinosaurGame():\n",
    "    def __init__(self, maximum = None):\n",
    "        self.time = 0\n",
    "        self.alive = True\n",
    "        self.WIDTH, self.HEIGHT = 800, 400\n",
    "\n",
    "        # Colors\n",
    "        self.WHITE = (255, 255, 255)\n",
    "        self.BLACK = (0, 0, 0)\n",
    "        # Dinosaur settings\n",
    "        self.dino_size = 50\n",
    "        self.dino_x = 80\n",
    "        self.dino_y = self.HEIGHT - self.dino_size - 40\n",
    "        self.dino_vel_y = 0\n",
    "        self.gravity = 2\n",
    "        self.jumping = False\n",
    "\n",
    "        # Obstacle settings\n",
    "        self.obstacle_width = 20\n",
    "        self.obstacle_height = 50\n",
    "        self.obstacle_x = self.WIDTH # 800\n",
    "        self.obstacle_y = self.HEIGHT - self.obstacle_height - 40\n",
    "        self.obstacle_speed = 10\n",
    "\n",
    "        # Game settings\n",
    "        self.running = True\n",
    "        self.jumping = False\n",
    "        self.score = 0\n",
    "        # self.font = pygame.font.Font(None, 36)\n",
    "\n",
    "        # Calc'd constants\n",
    "        self.cross_time = self.WIDTH / self.obstacle_speed\n",
    "\n",
    "        # Game loop\n",
    "        # self.clock = pygame.time.Clock()\n",
    "\n",
    "        if maximum:\n",
    "            self.maximum = maximum\n",
    "        else:\n",
    "            self.maximum = False\n",
    "\n",
    "    # def __len__(self):\n",
    "    #     return self.cross_time * self.maximum\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     return self.get_input(idx)\n",
    "\n",
    "    def get_input(self):\n",
    "        # Return input: 1 if obstacle, 0 if not (obstacles appear every few timesteps)\n",
    "        # TODO: Give position of obstacle just for funsies\n",
    "        # Could give distance btw obstacle and character\n",
    "        # Could give its own position & object's position\n",
    "        # cross_time = self.WIDTH / self.obstacle_speed\n",
    "        # obs_pos = (time % cross_time) * self.obstacle_speed\n",
    "        obs_pos = self.obstacle_x\n",
    "        if 441 <= obs_pos <= 459:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        # return [1 if self.time % 45 == 0 else 0]\n",
    "\n",
    "    def step(self, action):\n",
    "        # Event handling\n",
    "        # AI output: jump or not (each frame ig)\n",
    "        if action >= 1 and not self.jumping:\n",
    "            self.jumping = True\n",
    "            self.dino_vel_y = -20\n",
    "\n",
    "        # Dinosaur movement (jumping)\n",
    "        if self.jumping:\n",
    "            self.dino_y += self.dino_vel_y\n",
    "            self.dino_vel_y += self.gravity\n",
    "            if self.dino_y >= self.HEIGHT - self.dino_size - 40:\n",
    "                self.dino_y = self.HEIGHT - self.dino_size - 40\n",
    "                self.jumping = False\n",
    "\n",
    "        # Obstacle movement: Resets the same obstacle\n",
    "        # Can give AI input every time this if triggers\n",
    "        self.obstacle_x -= self.obstacle_speed\n",
    "        if self.obstacle_x < -self.obstacle_width:\n",
    "            self.obstacle_x = self.WIDTH\n",
    "            self.score += 1\n",
    "            # # Speeding up\n",
    "            # if self.score % 10 == 0:\n",
    "            #     self.obstacle_speed += 1\n",
    "\n",
    "        # # Collision detection\n",
    "        # dino_rect = pygame.Rect(self.dino_x, self.dino_y, self.dino_size, self.dino_size)\n",
    "        # obstacle_rect = pygame.Rect(self.obstacle_x, self.obstacle_y, self.obstacle_width, self.obstacle_height)\n",
    "        # if dino_rect.colliderect(obstacle_rect):\n",
    "        #     self.alive = False\n",
    "        self.alive = (self.dino_x + self.dino_size <= self.obstacle_x or self.obstacle_x + self.obstacle_width <= self.dino_x or self.dino_y + self.dino_size <= self.obstacle_y or self.obstacle_y + self.obstacle_height <= self.dino_y)\n",
    "\n",
    "        if self.maximum:\n",
    "            if self.score >= self.maximum:\n",
    "                self.alive = False\n",
    "\n",
    "        self.time += 1\n",
    "\n",
    "        # # Debug\n",
    "        # if generation >= 30:\n",
    "        #     time.sleep(0.00001)\n",
    "        # time.sleep(0.001)\n",
    "        # print(f'time: {self.time} action: {action}\\ndino_y: {self.dino_y}\\ndino_vel_y: {self.dino_vel_y}\\njumping: {self.jumping}')\n",
    "\n",
    "    def visualize(self, screen):\n",
    "        # Draws game state in pygame\n",
    "        dino_rect = pygame.Rect(self.dino_x, self.dino_y, self.dino_size, self.dino_size)\n",
    "        obstacle_rect = pygame.Rect(self.obstacle_x, self.obstacle_y, self.obstacle_width, self.obstacle_height)\n",
    "\n",
    "        # Draw dinosaur and obstacle\n",
    "        pygame.draw.rect(screen, self.BLACK, dino_rect)\n",
    "        pygame.draw.rect(screen, self.BLACK, obstacle_rect)\n",
    "\n",
    "        # Draw score\n",
    "        score_text = self.font.render(f\"Score: {self.score}\", True, self.BLACK)\n",
    "        screen.blit(score_text, (10, 10))\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() else\n",
    "        \"mps\" if torch.backends.mps.is_available() else\n",
    "        \"cpu\"\n",
    "    )\n",
    "\n",
    "    ## For multiprocessing\n",
    "    device = 'cpu'\n",
    "\n",
    "    torch.set_default_device(device)\n",
    "\n",
    "    # pygame.init()\n",
    "\n",
    "    # Define the parameters for the evolutionary process\n",
    "    pop_size = 10\n",
    "    num_generations = 600\n",
    "    n_offspring = 10\n",
    "    # mutation_rate = 0.05\n",
    "    mutation_rate = 0.5\n",
    "\n",
    "    # Create the Evolution object and run the evolution process\n",
    "    # \n",
    "    evolution = Evolution(RSNN2, (), {'num_inputs':1, 'num_hidden':20, 'num_outputs':1})\n",
    "    # Note: evolve method was altered from Ivyer's OG code so we code Dino-ify it :)\n",
    "    # done: change evolve, custom loss\n",
    "    # game_args: maximum=100\n",
    "    best_model, fitness, final_population = evolution.evolve(pop_size, n_offspring, num_generations, DinosaurGame, (100,), mutation_rate)\n",
    "    # ea.visualize_model(best_model, DinosaurGame, (100,))\n",
    "\n",
    "    # Save the best model's state dictionary\n",
    "    torch.save(best_model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    # Usage example after evolution process\n",
    "    initial_models = evolution.populate(pop_size)\n",
    "    best_perf = evolution.decode_population(evolution.encode_population([best_model]), best_model)\n",
    "\n",
    "    plot_connectivity_changes_heat(initial_models, final_population)\n",
    "\n",
    "\n",
    "    final_models = evolution.decode_population(evolution.encode_population([best_model]), best_model)\n",
    "    plot_connectivity_changes_line(initial_models, final_models)\n",
    "\n",
    "\n",
    "    print_model_performance(best_model, DinosaurGame, (100,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb5749-b896-409a-9a05-001a1df78f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 2/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 3/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 4/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 5/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 6/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 7/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 8/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 9/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 10/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 11/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 12/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 13/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 14/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 15/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 16/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 17/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 18/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 19/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 20/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 21/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 22/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 23/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 24/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 25/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 26/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 27/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 28/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 29/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 30/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 31/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 32/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 33/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 34/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 35/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 36/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 37/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 38/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 39/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 40/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 41/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 42/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 43/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 44/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 45/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 46/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 47/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 48/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 49/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 50/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 51/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 52/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 53/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 54/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 55/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 56/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 57/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 58/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 59/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 60/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 61/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 62/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 63/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 64/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 65/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 66/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 67/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 0\n",
      "Generation 68/600, Best Fitness: 0.8494999996328261\n",
      "Overall Best Fitness: 0.8494999996328261\n",
      "Generation 69/600, Best Fitness: 1.8419999959587585\n",
      "Overall Best Fitness: 1.8419999959587585\n",
      "Generation 70/600, Best Fitness: 1.8574999988195486\n",
      "Overall Best Fitness: 1.8574999988195486\n",
      "Generation 71/600, Best Fitness: 92.73600013644318\n",
      "Overall Best Fitness: 92.73600013644318\n",
      "Generation 72/600, Best Fitness: 92.74650013956125\n",
      "Overall Best Fitness: 92.74650013956125\n",
      "Generation 73/600, Best Fitness: 92.73600013644318\n",
      "Overall Best Fitness: 92.74650013956125\n",
      "Generation 74/600, Best Fitness: 92.73600013644318\n",
      "Overall Best Fitness: 92.74650013956125\n",
      "Generation 75/600, Best Fitness: 95.87499999956344\n",
      "Overall Best Fitness: 95.87499999956344\n",
      "Generation 76/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 95.87499999956344\n",
      "Generation 77/600, Best Fitness: 0.932100000733044\n",
      "Overall Best Fitness: 95.87499999956344\n",
      "Generation 78/600, Best Fitness: -0.027199999312870204\n",
      "Overall Best Fitness: 95.87499999956344\n",
      "Generation 79/600, Best Fitness: 0.8221000032499433\n",
      "Overall Best Fitness: 95.87499999956344\n",
      "Generation 80/600, Best Fitness: 96.07450002065161\n",
      "Overall Best Fitness: 96.07450002065161\n",
      "Generation 81/600, Best Fitness: 96.38000005215872\n",
      "Overall Best Fitness: 96.38000005215872\n",
      "Generation 82/600, Best Fitness: 96.38100005226443\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 83/600, Best Fitness: 96.38100005226443\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 84/600, Best Fitness: 96.38100005226443\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 85/600, Best Fitness: 96.36350004919223\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 86/600, Best Fitness: 96.38100005226443\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 87/600, Best Fitness: 96.38100005226443\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 88/600, Best Fitness: 96.38100005226443\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 89/600, Best Fitness: 96.38100005226443\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 90/600, Best Fitness: 96.38100005226443\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 91/600, Best Fitness: 96.38100005226443\n",
      "Overall Best Fitness: 96.38100005226443\n",
      "Generation 92/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 93/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 94/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 95/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 96/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 97/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 98/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 99/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 100/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 101/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 102/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 103/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 104/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 105/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 106/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 107/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 108/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 109/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 110/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 111/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 112/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 113/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 114/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 115/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 116/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 117/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 118/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 119/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 120/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 121/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 122/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 123/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 124/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 125/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 126/600, Best Fitness: 96.43000005744398\n",
      "Overall Best Fitness: 96.43000005744398\n",
      "Generation 127/600, Best Fitness: 96.47950006267638\n",
      "Overall Best Fitness: 96.47950006267638\n",
      "Generation 128/600, Best Fitness: 96.47950006267638\n",
      "Overall Best Fitness: 96.47950006267638\n",
      "Generation 129/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 130/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 131/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 132/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 133/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 134/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 135/600, Best Fitness: 96.47950006267638\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 136/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 137/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 138/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 139/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 140/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 141/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 142/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 143/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 144/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 145/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 146/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 147/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 148/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 149/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 150/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 151/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 152/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 153/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 154/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 155/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 156/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 157/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 158/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 159/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 160/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 161/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 162/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 163/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 164/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 165/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 166/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 167/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 168/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 169/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 170/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 171/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 172/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 173/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 174/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 175/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 176/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 177/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 178/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 179/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 180/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 181/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 182/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 183/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 184/600, Best Fitness: 96.48000006272923\n",
      "Overall Best Fitness: 96.48000006272923\n",
      "Generation 185/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 186/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 187/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 188/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 189/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 190/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 191/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 192/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 193/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 194/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 195/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 196/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 197/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 198/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 199/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 200/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 201/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 202/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 203/600, Best Fitness: 96.53000006801449\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 204/600, Best Fitness: 96.53000006801449\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 205/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 206/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 207/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 208/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 209/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 210/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 211/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 212/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 213/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 214/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 215/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 216/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 217/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 218/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 219/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 220/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 221/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 222/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 223/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 224/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 225/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 226/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 227/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 228/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 229/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 230/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 231/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 232/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 233/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 234/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 235/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 236/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 237/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 238/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 239/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 240/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 241/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 242/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 243/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 244/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 245/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 246/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 247/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 248/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 249/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 250/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 251/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 252/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 253/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 254/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 255/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 256/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 257/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 258/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 259/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 260/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 261/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 262/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 263/600, Best Fitness: 96.53000006801449\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 264/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 265/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 266/600, Best Fitness: 96.53000006801449\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 267/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 268/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 269/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n",
      "Generation 270/600, Best Fitness: 96.53050006806734\n",
      "Overall Best Fitness: 96.53050006806734\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18e427-1eac-4d27-be3f-5560dec5d14c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EA_ready_kernel",
   "language": "python",
   "name": "ea_ready_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
